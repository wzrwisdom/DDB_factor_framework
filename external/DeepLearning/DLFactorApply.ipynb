{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dolphindb as ddb\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from net import SimpleNet, MultiChannNet\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from dolphindb_tools.dataloader import DDBDataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructDataLoader():\n",
    "    s = ddb.session()\n",
    "    s.connect(\"127.0.0.1\", 11281, \"admin\", \"123456\")\n",
    "    \n",
    "    # 加载库表\n",
    "    dbPath = \"dfs://ai_dataloader\"\n",
    "    tbName = \"wide_factor_table_test\"\n",
    "    t1 = s.loadTable(tableName=tbName,dbPath=dbPath)\n",
    "    symbols = t1.exec(['distinct security_code']).toList().tolist()\n",
    "    symbols = [\"`\"+i for i in symbols]\n",
    "    times = t1.exec(['distinct trade_time']).toList().tolist()\n",
    "    times = [i.strftime(\"%Y.%m.%d\") for i in times]\n",
    "    times = list(set(times))\n",
    "    \n",
    "    sql = f\"\"\"select * from loadTable(\"{dbPath}\", \"{tbName}\")\"\"\"\n",
    "    \n",
    "    dataloader = DDBDataLoader(\n",
    "        s, sql, targetCol=[\"label\"], batchSize=64, shuffle=True,\n",
    "        windowSize=[1, 1], windowStride=[1, 1],\n",
    "        repartitionCol=\"date(trade_time)\", repartitionScheme=times,\n",
    "        groupCol=\"security_code\", groupScheme=symbols,\n",
    "        seed=0, offset=0,\n",
    "        excludeCol=[\"label\"], device=\"cuda\",\n",
    "        prefetchBatch=5, prepartitionNum=3\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批归一化前的张量： tensor([[-0.5726,  0.5194],\n",
      "        [ 1.0865, -1.8410],\n",
      "        [-1.3326, -0.2792]])\n",
      "批归一化后的张量： tensor([[-0.2967,  1.0742],\n",
      "        [ 1.3458, -1.3337],\n",
      "        [-1.0491,  0.2596]], grad_fn=<NativeBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 创建一个随机的三维张量\n",
    "# tensor = torch.randn(2, 3, 4)\n",
    "\n",
    "# # 对中间维度进行批归一化\n",
    "# batch_norm = nn.BatchNorm1d(4)\n",
    "# # output = batch_norm(tensor)\n",
    "# output = batch_norm(tensor.transpose(1, 2)).transpose(1, 2)\n",
    "\n",
    "tensor = torch.randn(3, 2)\n",
    "batch_norm = nn.BatchNorm1d(2)\n",
    "output = batch_norm(tensor)\n",
    "\n",
    "print(\"批归一化前的张量：\", tensor)\n",
    "print(\"批归一化后的张量：\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.973643e-08"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.transpose(0, 1)[0].detach().flatten().numpy().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8689510339124705"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].transpose(0, 1)[0].detach().numpy().std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name, model_pth_file):\n",
    "    if model_name == \"simple_model\":\n",
    "        model = SimpleNet(features_in=60)\n",
    "    elif model_name == \"multichann_model\":\n",
    "        model = MultiChannNet(features_in=6)\n",
    "    model.load_state_dict(torch.load(model_pth_file))\n",
    "    model = model.to(\"cuda\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_and_save(model, factor_name):\n",
    "    s = ddb.session()\n",
    "    s.connect(\"127.0.0.1\", 11281, \"admin\", \"123456\")\n",
    "    # 加载库表\n",
    "    dbPath = \"dfs://ai_dataloader\"\n",
    "    tbName = \"wide_factor_table_test\"\n",
    "    df = s.loadTable(tableName=tbName,dbPath=dbPath).toDF()\n",
    "    \n",
    "    dbPath_write = \"dfs://MIN_FACTOR_TSDB\"\n",
    "    tbName_write = \"min_factor\"\n",
    "    batchSize = 64\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for li in tqdm(range(0, df.shape[0], batchSize), mininterval=1):\n",
    "            ri = min(li+batchSize, df.shape[0])\n",
    "            \n",
    "            # apply model to x\n",
    "            x_df = df.iloc[li:ri, 2:-1]\n",
    "            x = torch.tensor(x_df.values).reshape(-1, 1, 60)\n",
    "            x = x.to(\"cuda\")\n",
    "            y_pred = model(x)\n",
    "            \n",
    "            # save factor values into table\n",
    "            basicInfo_df = df.iloc[li:ri, :2]\n",
    "            basicInfo_df[\"factor_code\"] = factor_name\n",
    "            basicInfo_df[\"value\"] = y_pred.flatten().cpu().detach().numpy() \n",
    "            s.run(\"tableInsert{{loadTable('{db}', `{tb})}}\".format(db=dbPath_write,tb=tbName_write), basicInfo_df)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9237/9237 [06:11<00:00, 24.87it/s]  \n"
     ]
    }
   ],
   "source": [
    "# load model parameters and create a model object\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "model_name = \"simple_model\"\n",
    "model_pth_file = f\"./models/{model_name}_old.pth\"\n",
    "model = get_model(model_name, model_pth_file)\n",
    "\n",
    "# # get a dataloader\n",
    "# dataloader = constructDataLoader()\n",
    "\n",
    "apply_and_save(model, factor_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9237/9237 [06:29<00:00, 23.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# load model parameters and create a model object\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "model_name = \"multichann_model\"\n",
    "model_pth_file = f\"./models/{model_name}_old.pth\"\n",
    "model = get_model(model_name, model_pth_file)\n",
    "\n",
    "# # get a dataloader\n",
    "# dataloader = constructDataLoader()\n",
    "apply_and_save(model, factor_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4762it [02:26, 32.85it/s]Exception ignored in: <function DataManager.__del__ at 0x7ff2b566d4d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wangzirui/miniconda3/envs/myenv/lib/python3.7/site-packages/dolphindb_tools/dataloader/datamanager.py\", line 56, in __del__\n",
      "    self.exit()\n",
      "  File \"/home/wangzirui/miniconda3/envs/myenv/lib/python3.7/site-packages/dolphindb_tools/dataloader/datamanager.py\", line 63, in exit\n",
      "    self.join()\n",
      "  File \"/home/wangzirui/miniconda3/envs/myenv/lib/python3.7/site-packages/dolphindb_tools/dataloader/datamanager.py\", line 51, in join\n",
      "    self.back_thread.join()\n",
      "  File \"/home/wangzirui/miniconda3/envs/myenv/lib/python3.7/threading.py\", line 1041, in join\n",
      "    raise RuntimeError(\"cannot join current thread\")\n",
      "RuntimeError: cannot join current thread\n",
      "8749it [04:31, 31.84it/s]Exception ignored in: <function DataManager.__del__ at 0x7ff2b566d4d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wangzirui/miniconda3/envs/myenv/lib/python3.7/site-packages/dolphindb_tools/dataloader/datamanager.py\", line 56, in __del__\n",
      "    self.exit()\n",
      "  File \"/home/wangzirui/miniconda3/envs/myenv/lib/python3.7/site-packages/dolphindb_tools/dataloader/datamanager.py\", line 63, in exit\n",
      "    self.join()\n",
      "  File \"/home/wangzirui/miniconda3/envs/myenv/lib/python3.7/site-packages/dolphindb_tools/dataloader/datamanager.py\", line 51, in join\n",
      "    self.back_thread.join()\n",
      "  File \"/home/wangzirui/miniconda3/envs/myenv/lib/python3.7/threading.py\", line 1041, in join\n",
      "    raise RuntimeError(\"cannot join current thread\")\n",
      "RuntimeError: cannot join current thread\n",
      "9237it [12:58, 11.86it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3293/127804665.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_pred_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmininterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.7/site-packages/dolphindb_tools/dataloader/dataloader.py\u001b[0m in \u001b[0;36m_get_next_batch_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    244\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mback_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_pred_list = []\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(dataloader, mininterval=1):\n",
    "        x = x.to(\"cuda\")\n",
    "        y = y.to(\"cuda\")\n",
    "        y_pred = model(x)\n",
    "        y_pred_list.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(y_pred_list[:2]).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
